{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MZIjavb0Vb21"
   },
   "source": [
    "# Set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 80
    },
    "colab_type": "code",
    "collapsed": true,
    "executionInfo": {
     "elapsed": 3498,
     "status": "ok",
     "timestamp": 1574523221746,
     "user": {
      "displayName": "MIZUHIRO SUZUKI",
      "photoUrl": "",
      "userId": "11994014812088599130"
     },
     "user_tz": 360
    },
    "id": "nwbCYEDnVeVW",
    "outputId": "95877226-7bff-48db-a2f1-7dc012b1cf99"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p style=\"color: red;\">\n",
       "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
       "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
       "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
       "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "from keras import datasets, layers, models\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, LambdaCallback, Callback\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.preprocessing import image as krs_image\n",
    "from keras.models import Sequential, Model, load_model\n",
    "from keras.layers import Flatten, Input, concatenate\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "from keras.layers.core import Activation, Dropout, Dense\n",
    "from keras.optimizers import Adam\n",
    "import keras.backend as K\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer, MinMaxScaler\n",
    "from sklearn.utils import class_weight\n",
    "import random\n",
    "from glob import glob\n",
    "import tempfile\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jLBnFge9fFaZ"
   },
   "source": [
    "## Generator to load datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qBjJHoRBL7LP"
   },
   "outputs": [],
   "source": [
    "\n",
    "def custom_generator(images_list, dataframe, lb_label, continuous_var_list, categorical_var_list, minmaxscaler, lb_list, batch_size, mode, augment = None):\n",
    "    i = 0\n",
    "    # if not evaluation generator, shuffle the image \n",
    "    if mode == 'train':\n",
    "        random.shuffle(images_list)\n",
    "    while True:        \n",
    "        images = []\n",
    "        csv_continuous_features = []\n",
    "        csv_categorical_features = []\n",
    "        labels = []\n",
    "        \n",
    "        while len(images) < batch_size:\n",
    "            if i == len(images_list):\n",
    "                # if evaluation generator, break the loop when the last image is retrieved\n",
    "                if mode == 'eval':\n",
    "                    break\n",
    "                i = 0\n",
    "                random.shuffle(images_list)                \n",
    "                  \n",
    "            # Read image from list and convert to array\n",
    "            image_path = images_list[i]\n",
    "            image_name = os.path.basename(image_path).replace('.jpg', '')\n",
    "            image = krs_image.load_img(image_path, target_size=(IMG_HEIGHT, IMG_WIDTH))\n",
    "            image = np.asarray(image)\n",
    "            images.append(image)\n",
    "\n",
    "            # Read data from csv using the name of current image\n",
    "            csv_row = dataframe[dataframe.id == image_name]\n",
    "            \n",
    "            # extract continuous features\n",
    "            csv_continuous_features.append(np.array(csv_row[continuous_var_list])[0])\n",
    "            \n",
    "            # extract categorical features\n",
    "            csv_categorical_features.append(np.array(csv_row[categorical_var_list])[0])\n",
    "\n",
    "            # # just to check if data are correctly retrieved...\n",
    "            # print(image_name)\n",
    "            \n",
    "            if mode == 'train':\n",
    "                label = np.array(csv_row['label'])[0]\n",
    "                labels.append(label)\n",
    "\n",
    "            i += 1\n",
    "\n",
    "        images = np.array(images)\n",
    "        if augment != None:\n",
    "            if mode == 'train':\n",
    "                (images, labels) = next(augment.flow(images, labels, batch_size = batch_size, shuffle = False))\n",
    "            elif mode == 'eval':\n",
    "                images = next(augment.flow(images, batch_size = batch_size, shuffle = False))\n",
    "        elif augment == None:\n",
    "            datagen_rescale = ImageDataGenerator(rescale = 1./255, featurewise_center = True)\n",
    "            datagen_rescale.mean = [train_data.R_mean.mean() / 255, train_data.G_mean.mean() / 255, train_data.B_mean.mean() / 255]\n",
    "            if mode == 'train':\n",
    "                (images, labels) = next(datagen_rescale.flow(images, labels, batch_size = batch_size, shuffle = False))\n",
    "            elif mode == 'eval':\n",
    "                images = next(datagen_rescale.flow(images, batch_size = batch_size, shuffle = False))\n",
    "            \n",
    "        # rescale continuous features\n",
    "        csv_continuous_features = minmaxscaler.transform(np.array(csv_continuous_features))\n",
    "        \n",
    "        # convert categorical features into one-hot encoding\n",
    "        csv_categorical_features_temp = lb_list[0].transform(np.array(csv_categorical_features)[:, 0])\n",
    "        \n",
    "        if len(categorical_var_list) > 0:\n",
    "            for j in range(1, len(categorical_var_list)):\n",
    "                np.hstack(csv_categorical_features_temp, lb_list[j].transform(csv_categorical_features_temp[:, j]))\n",
    "        csv_categorical_features = csv_categorical_features_temp\n",
    "        \n",
    "        csv = np.hstack([csv_continuous_features, csv_categorical_features])\n",
    "        \n",
    "        if mode == 'train':\n",
    "            labels = lb_label.transform(labels)\n",
    "            yield [np.array(images), csv], labels\n",
    "        elif mode == 'eval':\n",
    "            yield [np.array(images), csv]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hktipl5GL7ku"
   },
   "source": [
    "## Define models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hqUBGgC9h2Yr"
   },
   "source": [
    "### Model for training with early stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Cy_F8orGfHey"
   },
   "outputs": [],
   "source": [
    "batch_size = 48\n",
    "IMG_HEIGHT = 224\n",
    "IMG_WIDTH = 224\n",
    "path = '/content/drive/My Drive/stac/'\n",
    "train_dir = os.path.join(path, 'image_mask/train/')\n",
    "test_dir = os.path.join(path, 'image_mask/test/')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "j6VhUyLQftMU"
   },
   "outputs": [],
   "source": [
    "train_data_csv = pd.read_csv(os.path.join(path, 'image_mask/train/train_data_with_dist.csv'))\n",
    "test_data_csv = pd.read_csv(os.path.join(path, 'image_mask/test/test_data_with_dist.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 261
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 834,
     "status": "ok",
     "timestamp": 1574523404339,
     "user": {
      "displayName": "MIZUHIRO SUZUKI",
      "photoUrl": "",
      "userId": "11994014812088599130"
     },
     "user_tz": 360
    },
    "id": "KvAxsdsmYTXE",
    "outputId": "af5b7cb1-c581-47f8-cd3f-4cc86f0953c6"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>centroid_x</th>\n",
       "      <th>centroid_y</th>\n",
       "      <th>log_building_area</th>\n",
       "      <th>building_vertices</th>\n",
       "      <th>building_width</th>\n",
       "      <th>building_height</th>\n",
       "      <th>place</th>\n",
       "      <th>R_mean</th>\n",
       "      <th>G_mean</th>\n",
       "      <th>B_mean</th>\n",
       "      <th>R_std</th>\n",
       "      <th>G_std</th>\n",
       "      <th>B_std</th>\n",
       "      <th>H_mean</th>\n",
       "      <th>S_mean</th>\n",
       "      <th>V_mean</th>\n",
       "      <th>H_std</th>\n",
       "      <th>S_std</th>\n",
       "      <th>V_std</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>distance_10_all</th>\n",
       "      <th>distance_20_all</th>\n",
       "      <th>distance_50_all</th>\n",
       "      <th>distance_10_train</th>\n",
       "      <th>distance_20_train</th>\n",
       "      <th>distance_50_train</th>\n",
       "      <th>concrete_10_train</th>\n",
       "      <th>healthy_10_train</th>\n",
       "      <th>incomplete_10_train</th>\n",
       "      <th>irregular_10_train</th>\n",
       "      <th>other_10_train</th>\n",
       "      <th>concrete_20_train</th>\n",
       "      <th>healthy_20_train</th>\n",
       "      <th>incomplete_20_train</th>\n",
       "      <th>irregular_20_train</th>\n",
       "      <th>other_20_train</th>\n",
       "      <th>concrete_50_train</th>\n",
       "      <th>healthy_50_train</th>\n",
       "      <th>incomplete_50_train</th>\n",
       "      <th>irregular_50_train</th>\n",
       "      <th>other_50_train</th>\n",
       "      <th>filename</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>7a3f2a10</td>\n",
       "      <td>concrete_cement</td>\n",
       "      <td>-74.158686</td>\n",
       "      <td>4.555175</td>\n",
       "      <td>-18.936547</td>\n",
       "      <td>5</td>\n",
       "      <td>9.549665</td>\n",
       "      <td>13.229584</td>\n",
       "      <td>borde_rural</td>\n",
       "      <td>77.854895</td>\n",
       "      <td>73.351518</td>\n",
       "      <td>146.993500</td>\n",
       "      <td>67.880480</td>\n",
       "      <td>64.434540</td>\n",
       "      <td>125.473623</td>\n",
       "      <td>0.063230</td>\n",
       "      <td>0.054169</td>\n",
       "      <td>0.316736</td>\n",
       "      <td>0.056303</td>\n",
       "      <td>0.072556</td>\n",
       "      <td>0.274796</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.461538</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>7a3f2a10.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>7a1f731e</td>\n",
       "      <td>irregular_metal</td>\n",
       "      <td>-74.158750</td>\n",
       "      <td>4.555195</td>\n",
       "      <td>-18.939354</td>\n",
       "      <td>5</td>\n",
       "      <td>10.043447</td>\n",
       "      <td>12.529615</td>\n",
       "      <td>borde_rural</td>\n",
       "      <td>124.694521</td>\n",
       "      <td>124.628628</td>\n",
       "      <td>147.602022</td>\n",
       "      <td>108.855020</td>\n",
       "      <td>109.155474</td>\n",
       "      <td>125.356539</td>\n",
       "      <td>0.271230</td>\n",
       "      <td>0.022647</td>\n",
       "      <td>0.493386</td>\n",
       "      <td>0.253855</td>\n",
       "      <td>0.036350</td>\n",
       "      <td>0.429687</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>7a1f731e.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>7a424ad8</td>\n",
       "      <td>healthy_metal</td>\n",
       "      <td>-74.158802</td>\n",
       "      <td>4.555230</td>\n",
       "      <td>-19.628413</td>\n",
       "      <td>5</td>\n",
       "      <td>7.561388</td>\n",
       "      <td>7.970262</td>\n",
       "      <td>borde_rural</td>\n",
       "      <td>135.498841</td>\n",
       "      <td>136.810501</td>\n",
       "      <td>154.154495</td>\n",
       "      <td>109.534520</td>\n",
       "      <td>110.653357</td>\n",
       "      <td>123.881052</td>\n",
       "      <td>0.323498</td>\n",
       "      <td>0.020789</td>\n",
       "      <td>0.537306</td>\n",
       "      <td>0.267187</td>\n",
       "      <td>0.018401</td>\n",
       "      <td>0.434195</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>19</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>7a424ad8.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>7a3edc5e</td>\n",
       "      <td>healthy_metal</td>\n",
       "      <td>-74.158993</td>\n",
       "      <td>4.554755</td>\n",
       "      <td>-18.914724</td>\n",
       "      <td>5</td>\n",
       "      <td>10.414648</td>\n",
       "      <td>12.632232</td>\n",
       "      <td>borde_rural</td>\n",
       "      <td>135.939801</td>\n",
       "      <td>135.257038</td>\n",
       "      <td>144.207639</td>\n",
       "      <td>119.120671</td>\n",
       "      <td>118.611700</td>\n",
       "      <td>125.867072</td>\n",
       "      <td>0.263625</td>\n",
       "      <td>0.021276</td>\n",
       "      <td>0.533524</td>\n",
       "      <td>0.236370</td>\n",
       "      <td>0.019511</td>\n",
       "      <td>0.467427</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "      <td>59</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>39</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.187500</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.562500</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.068182</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.568182</td>\n",
       "      <td>0.022727</td>\n",
       "      <td>7a3edc5e.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>7a303a6e</td>\n",
       "      <td>healthy_metal</td>\n",
       "      <td>-74.158795</td>\n",
       "      <td>4.554937</td>\n",
       "      <td>-19.027574</td>\n",
       "      <td>5</td>\n",
       "      <td>13.587928</td>\n",
       "      <td>10.044892</td>\n",
       "      <td>borde_rural</td>\n",
       "      <td>104.500974</td>\n",
       "      <td>102.593758</td>\n",
       "      <td>124.069303</td>\n",
       "      <td>108.094900</td>\n",
       "      <td>106.310129</td>\n",
       "      <td>126.937176</td>\n",
       "      <td>0.182812</td>\n",
       "      <td>0.017346</td>\n",
       "      <td>0.410758</td>\n",
       "      <td>0.200787</td>\n",
       "      <td>0.021575</td>\n",
       "      <td>0.424660</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.129032</td>\n",
       "      <td>0.193548</td>\n",
       "      <td>0.064516</td>\n",
       "      <td>0.580645</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>7a303a6e.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0        id  ... other_50_train      filename\n",
       "0           0  7a3f2a10  ...       0.076923  7a3f2a10.jpg\n",
       "1           1  7a1f731e  ...       0.071429  7a1f731e.jpg\n",
       "2           2  7a424ad8  ...       0.066667  7a424ad8.jpg\n",
       "3           3  7a3edc5e  ...       0.022727  7a3edc5e.jpg\n",
       "4           4  7a303a6e  ...       0.032258  7a303a6e.jpg\n",
       "\n",
       "[5 rows x 45 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_csv['filename'] = train_data_csv.id + '.jpg'\n",
    "train_data_csv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 261
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 832,
     "status": "ok",
     "timestamp": 1574523409447,
     "user": {
      "displayName": "MIZUHIRO SUZUKI",
      "photoUrl": "",
      "userId": "11994014812088599130"
     },
     "user_tz": 360
    },
    "id": "zqt4dr-6anK5",
    "outputId": "4e66eb31-285a-4599-c2be-35ba274c16d1"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>centroid_x</th>\n",
       "      <th>centroid_y</th>\n",
       "      <th>log_building_area</th>\n",
       "      <th>building_vertices</th>\n",
       "      <th>building_width</th>\n",
       "      <th>building_height</th>\n",
       "      <th>place</th>\n",
       "      <th>R_mean</th>\n",
       "      <th>G_mean</th>\n",
       "      <th>B_mean</th>\n",
       "      <th>R_std</th>\n",
       "      <th>G_std</th>\n",
       "      <th>B_std</th>\n",
       "      <th>H_mean</th>\n",
       "      <th>S_mean</th>\n",
       "      <th>V_mean</th>\n",
       "      <th>H_std</th>\n",
       "      <th>S_std</th>\n",
       "      <th>V_std</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>distance_10_all</th>\n",
       "      <th>distance_20_all</th>\n",
       "      <th>distance_50_all</th>\n",
       "      <th>distance_10_train</th>\n",
       "      <th>distance_20_train</th>\n",
       "      <th>distance_50_train</th>\n",
       "      <th>concrete_10_train</th>\n",
       "      <th>healthy_10_train</th>\n",
       "      <th>incomplete_10_train</th>\n",
       "      <th>irregular_10_train</th>\n",
       "      <th>other_10_train</th>\n",
       "      <th>concrete_20_train</th>\n",
       "      <th>healthy_20_train</th>\n",
       "      <th>incomplete_20_train</th>\n",
       "      <th>irregular_20_train</th>\n",
       "      <th>other_20_train</th>\n",
       "      <th>concrete_50_train</th>\n",
       "      <th>healthy_50_train</th>\n",
       "      <th>incomplete_50_train</th>\n",
       "      <th>irregular_50_train</th>\n",
       "      <th>other_50_train</th>\n",
       "      <th>filename</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>7a4d630a</td>\n",
       "      <td>-74.158953</td>\n",
       "      <td>4.554654</td>\n",
       "      <td>-19.139941</td>\n",
       "      <td>5</td>\n",
       "      <td>10.039401</td>\n",
       "      <td>9.375537</td>\n",
       "      <td>borde_rural</td>\n",
       "      <td>123.915329</td>\n",
       "      <td>127.008717</td>\n",
       "      <td>160.728248</td>\n",
       "      <td>94.568756</td>\n",
       "      <td>96.901490</td>\n",
       "      <td>122.426289</td>\n",
       "      <td>0.333620</td>\n",
       "      <td>0.055182</td>\n",
       "      <td>0.499930</td>\n",
       "      <td>0.260862</td>\n",
       "      <td>0.050494</td>\n",
       "      <td>0.381395</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "      <td>54</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>36</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>0.235294</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>0.411765</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.073171</td>\n",
       "      <td>0.268293</td>\n",
       "      <td>0.073171</td>\n",
       "      <td>0.560976</td>\n",
       "      <td>0.024390</td>\n",
       "      <td>7a4d630a.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>7a4bbbd6</td>\n",
       "      <td>-74.159509</td>\n",
       "      <td>4.554677</td>\n",
       "      <td>-19.125909</td>\n",
       "      <td>5</td>\n",
       "      <td>8.930837</td>\n",
       "      <td>13.331169</td>\n",
       "      <td>borde_rural</td>\n",
       "      <td>103.174164</td>\n",
       "      <td>98.903974</td>\n",
       "      <td>129.441246</td>\n",
       "      <td>102.110107</td>\n",
       "      <td>98.049362</td>\n",
       "      <td>126.917853</td>\n",
       "      <td>0.138211</td>\n",
       "      <td>0.023418</td>\n",
       "      <td>0.405354</td>\n",
       "      <td>0.144369</td>\n",
       "      <td>0.027564</td>\n",
       "      <td>0.400830</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>53</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>41</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.065217</td>\n",
       "      <td>0.347826</td>\n",
       "      <td>0.086957</td>\n",
       "      <td>0.478261</td>\n",
       "      <td>0.021739</td>\n",
       "      <td>7a4bbbd6.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>7a4ac744</td>\n",
       "      <td>-74.158910</td>\n",
       "      <td>4.555028</td>\n",
       "      <td>-19.116754</td>\n",
       "      <td>5</td>\n",
       "      <td>8.372523</td>\n",
       "      <td>12.637685</td>\n",
       "      <td>borde_rural</td>\n",
       "      <td>122.421879</td>\n",
       "      <td>119.100460</td>\n",
       "      <td>146.136707</td>\n",
       "      <td>107.017083</td>\n",
       "      <td>104.601871</td>\n",
       "      <td>125.512256</td>\n",
       "      <td>0.189898</td>\n",
       "      <td>0.020047</td>\n",
       "      <td>0.480388</td>\n",
       "      <td>0.173220</td>\n",
       "      <td>0.035861</td>\n",
       "      <td>0.419911</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>26</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.129032</td>\n",
       "      <td>0.225806</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.580645</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>7a4ac744.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>7a4881fa</td>\n",
       "      <td>-74.158861</td>\n",
       "      <td>4.555007</td>\n",
       "      <td>-19.178307</td>\n",
       "      <td>5</td>\n",
       "      <td>7.844693</td>\n",
       "      <td>12.018867</td>\n",
       "      <td>borde_rural</td>\n",
       "      <td>112.187198</td>\n",
       "      <td>107.693765</td>\n",
       "      <td>153.989872</td>\n",
       "      <td>95.124870</td>\n",
       "      <td>92.243979</td>\n",
       "      <td>124.043331</td>\n",
       "      <td>0.113918</td>\n",
       "      <td>0.040184</td>\n",
       "      <td>0.448283</td>\n",
       "      <td>0.135922</td>\n",
       "      <td>0.046959</td>\n",
       "      <td>0.376538</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>26</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.129032</td>\n",
       "      <td>0.225806</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.580645</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>7a4881fa.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>7a4aa4a8</td>\n",
       "      <td>-74.158777</td>\n",
       "      <td>4.554996</td>\n",
       "      <td>-18.840272</td>\n",
       "      <td>5</td>\n",
       "      <td>14.114200</td>\n",
       "      <td>10.788166</td>\n",
       "      <td>borde_rural</td>\n",
       "      <td>109.659702</td>\n",
       "      <td>108.746657</td>\n",
       "      <td>133.855902</td>\n",
       "      <td>106.682311</td>\n",
       "      <td>106.374756</td>\n",
       "      <td>126.848866</td>\n",
       "      <td>0.207272</td>\n",
       "      <td>0.032812</td>\n",
       "      <td>0.436992</td>\n",
       "      <td>0.231152</td>\n",
       "      <td>0.049795</td>\n",
       "      <td>0.422201</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>22</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.148148</td>\n",
       "      <td>0.185185</td>\n",
       "      <td>0.037037</td>\n",
       "      <td>0.592593</td>\n",
       "      <td>0.037037</td>\n",
       "      <td>7a4aa4a8.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0        id  ...  other_50_train      filename\n",
       "0           0  7a4d630a  ...        0.024390  7a4d630a.jpg\n",
       "1           1  7a4bbbd6  ...        0.021739  7a4bbbd6.jpg\n",
       "2           2  7a4ac744  ...        0.032258  7a4ac744.jpg\n",
       "3           3  7a4881fa  ...        0.032258  7a4881fa.jpg\n",
       "4           4  7a4aa4a8  ...        0.037037  7a4aa4a8.jpg\n",
       "\n",
       "[5 rows x 44 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data_csv['filename'] = test_data_csv.id + '.jpg'\n",
    "test_data_csv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XK9rBNX3al5g"
   },
   "outputs": [],
   "source": [
    "train_data, valid_data, train_label, valid_label = train_test_split(train_data_csv, \n",
    "                                                                    train_data_csv.label, \n",
    "                                                                    test_size = 0.25, \n",
    "                                                                    stratify = train_data_csv.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nd67ejcVn4oi"
   },
   "outputs": [],
   "source": [
    "total_train = len(train_data)\n",
    "total_valid = len(valid_data)\n",
    "total_test = len(test_data_csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Tr2S6f00iKEY"
   },
   "source": [
    "#### Preparation for loading data with generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Oz2CEyM1iIq8"
   },
   "outputs": [],
   "source": [
    "# Specify which variables are used in NN\n",
    "\n",
    "# continuous_var_list = ['centroid_x', 'centroid_y', 'log_building_area', 'building_vertices', 'building_width', 'building_height']\n",
    "continuous_var_list = ['log_building_area', 'building_vertices', 'building_width', 'building_height',\n",
    "                        'R_mean', 'G_mean', 'B_mean', 'R_std', 'G_std', 'B_std',\n",
    "                        'distance_10_all', 'distance_20_all', 'distance_50_all',\n",
    "                        'concrete_10_train', 'healthy_10_train', 'incomplete_10_train', 'irregular_10_train', 'other_10_train',\n",
    "                        'concrete_20_train', 'healthy_20_train', 'incomplete_20_train', 'irregular_20_train', 'other_20_train',\n",
    "                       'concrete_50_train', 'healthy_50_train', 'incomplete_50_train', 'irregular_50_train', 'other_50_train']\n",
    "categorical_var_list = ['place']\n",
    "\n",
    "# Define a rescaler so that continuous variables are within the range of [0, 1]\n",
    "minmaxscaler = MinMaxScaler()\n",
    "minmaxscaler.fit(train_data_csv[continuous_var_list])\n",
    "\n",
    "# Define one-hot encoders for categorical variables\n",
    "lb0 = LabelBinarizer()\n",
    "lb0.fit(train_data_csv[categorical_var_list[0]])\n",
    "lb_list = [lb0]\n",
    "\n",
    "# Define a one-hot encoder for label\n",
    "lb_label = LabelBinarizer()\n",
    "lb_label.fit(train_data_csv.label)\n",
    "\n",
    "# Create an empty data generator, which will be used in training data generator\n",
    "datagen = ImageDataGenerator(rescale = 1./255,\n",
    "                            horizontal_flip = True,\n",
    "                            vertical_flip = True,\n",
    "                            rotation_range = 45,\n",
    "                            featurewise_center = True)\n",
    "datagen.mean = [train_data.R_mean.mean() / 255, train_data.G_mean.mean() / 255, train_data.B_mean.mean() / 255]\n",
    "\n",
    "datagen_test = ImageDataGenerator(rescale = 1./255,\n",
    "                                  shear_range=0.1,\n",
    "                                  zoom_range=0.1,\n",
    "                                  horizontal_flip=True,\n",
    "                                  vertical_flip=True,\n",
    "                                  rotation_range=10.,\n",
    "                                  width_shift_range = 0.1,\n",
    "                                  height_shift_range = 0.1,\n",
    "                                  featurewise_center = True)\n",
    "datagen_test.mean = [train_data.R_mean.mean() / 255, train_data.G_mean.mean() / 255, train_data.B_mean.mean() / 255]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xJv4SilgjUzK"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Read the image list and csv\n",
    "path = '/content/drive/My Drive/stac/'\n",
    "train_image_file_list = glob(os.path.join(path, 'image_mask/train/*.jpg'))\n",
    "test_image_file_list = glob(os.path.join(path, 'image_mask/test/*.jpg'))\n",
    "\n",
    "valid_image_file_index = [os.path.basename(train_image_file_list[i]).replace('.jpg','') in list(valid_data.id) for i in range(len(train_image_file_list))]\n",
    "train_image_file_index = [os.path.basename(train_image_file_list[i]).replace('.jpg','') in list(train_data.id) for i in range(len(train_image_file_list))]\n",
    "valid_image_file_list = list(np.array(train_image_file_list)[valid_image_file_index])\n",
    "train_image_file_list = list(np.array(train_image_file_list)[train_image_file_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NFPlFa9FjtRn"
   },
   "outputs": [],
   "source": [
    "train_data_generator = custom_generator(train_image_file_list, train_data, \n",
    "                                         lb_label, continuous_var_list, categorical_var_list, \n",
    "                                         minmaxscaler, lb_list, \n",
    "                                         batch_size, mode = 'train', augment = datagen)\n",
    "\n",
    "validation_data_generator = custom_generator(valid_image_file_list, valid_data, \n",
    "                                             lb_label, continuous_var_list, categorical_var_list, \n",
    "                                             minmaxscaler, lb_list, \n",
    "                                             batch_size, mode = 'train', augment = None)\n",
    "\n",
    "test_data_generator = custom_generator(test_image_file_list, test_data_csv, \n",
    "                                         lb_label, continuous_var_list, categorical_var_list, \n",
    "                                         minmaxscaler, lb_list, \n",
    "                                         batch_size, mode = 'eval', augment = datagen_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0dexiFhFuxzI"
   },
   "outputs": [],
   "source": [
    "num_categorical_var = 0\n",
    "for i in range(len(categorical_var_list)):\n",
    "  num_categorical_var += len(train_data[categorical_var_list[i]].unique())\n",
    "total_num_var = len(continuous_var_list) + num_categorical_var"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ft8FE-w5jevW"
   },
   "source": [
    "## Learning rate finder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eQtNg1n2kFGO"
   },
   "source": [
    "I am using a code posted at [`pyimagesearch.com`](https://www.pyimagesearch.com/2019/08/05/keras-learning-rate-finder/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OAN-VjdNkEme"
   },
   "outputs": [],
   "source": [
    "class LearningRateFinder:\n",
    "    def __init__(self, model, stopFactor=4, beta=0.98):\n",
    "        # store the model, stop factor, and beta value (for computing\n",
    "        # a smoothed, average loss)\n",
    "        self.model = model\n",
    "        self.stopFactor = stopFactor\n",
    "        self.beta = beta\n",
    " \n",
    "        # initialize our list of learning rates and losses,\n",
    "        # respectively\n",
    "        self.lrs = []\n",
    "        self.losses = []\n",
    "\n",
    "        # initialize our learning rate multiplier, average loss, best\n",
    "        # loss found thus far, current batch number, and weights file\n",
    "        self.lrMult = 1\n",
    "        self.avgLoss = 0\n",
    "        self.bestLoss = 1e9\n",
    "        self.batchNum = 0\n",
    "        self.weightsFile = None\n",
    "\n",
    "    def reset(self):\n",
    "        # re-initialize all variables from our constructor\n",
    "        self.lrs = []\n",
    "        self.losses = []\n",
    "        self.lrMult = 1\n",
    "        self.avgLoss = 0\n",
    "        self.bestLoss = 1e9\n",
    "        self.batchNum = 0\n",
    "        self.weightsFile = None\n",
    "    \n",
    "    def is_data_iter(self, data):\n",
    "        # define the set of class types we will check for\n",
    "        iterClasses = [\"NumpyArrayIterator\", \"DirectoryIterator\", \"DataFrameIterator\", \"Iterator\", \"Sequence\"]\n",
    "\n",
    "        # return whether our data is an iterator\n",
    "        return data.__class__.__name__ in iterClasses\n",
    "  \n",
    "    def on_batch_end(self, batch, logs):\n",
    "        # grab the current learning rate and add log it to the list of\n",
    "        # learning rates that we've tried\n",
    "        lr = K.get_value(self.model.optimizer.lr)\n",
    "        self.lrs.append(lr)\n",
    "\n",
    "        # grab the loss at the end of this batch, increment the total\n",
    "        # number of batches processed, compute the average average\n",
    "        # loss, smooth it, and update the losses list with the\n",
    "        # smoothed value\n",
    "        l = logs[\"loss\"]\n",
    "        self.batchNum += 1\n",
    "        self.avgLoss = (self.beta * self.avgLoss) + ((1 - self.beta) * l)\n",
    "        smooth = self.avgLoss / (1 - (self.beta ** self.batchNum))\n",
    "        self.losses.append(smooth)\n",
    "\n",
    "        # compute the maximum loss stopping factor value\n",
    "        stopLoss = self.stopFactor * self.bestLoss\n",
    "\n",
    "        # check to see whether the loss has grown too large\n",
    "        if self.batchNum > 1 and smooth > stopLoss:\n",
    "            # stop returning and return from the method\n",
    "            self.model.stop_training = True\n",
    "            return\n",
    "\n",
    "        # check to see if the best loss should be updated\n",
    "        if self.batchNum == 1 or smooth < self.bestLoss:\n",
    "            self.bestLoss = smooth\n",
    "\n",
    "        # increase the learning rate\n",
    "        lr *= self.lrMult\n",
    "        K.set_value(self.model.optimizer.lr, lr)  \n",
    "\n",
    "    def find(self, trainData, startLR, endLR, epochs=None,\n",
    "        stepsPerEpoch=None, batchSize=32, sampleSize=2048,\n",
    "        verbose=1, useGen = True):\n",
    "        # reset our class-specific variables\n",
    "        self.reset()\n",
    "\n",
    "        # # determine if we are using a data generator or not\n",
    "        # useGen = self.is_data_iter(trainData)\n",
    "\n",
    "        # if we're using a generator and the steps per epoch is not\n",
    "        # supplied, raise an error\n",
    "        if useGen and stepsPerEpoch is None:\n",
    "            msg = \"Using generator without supplying stepsPerEpoch\"\n",
    "            raise Exception(msg)\n",
    "\n",
    "        # if we're not using a generator then our entire dataset must\n",
    "        # already be in memory\n",
    "        elif not useGen:\n",
    "            # grab the number of samples in the training data and\n",
    "            # then derive the number of steps per epoch\n",
    "            numSamples = len(trainData[0])\n",
    "            stepsPerEpoch = np.ceil(numSamples / float(batchSize))\n",
    "\n",
    "        # if no number of training epochs are supplied, compute the\n",
    "        # training epochs based on a default sample size\n",
    "        if epochs is None:\n",
    "            epochs = int(np.ceil(sampleSize / float(stepsPerEpoch)))\n",
    "\n",
    "        # compute the total number of batch updates that will take\n",
    "        # place while we are attempting to find a good starting\n",
    "        # learning rate\n",
    "        numBatchUpdates = epochs * stepsPerEpoch\n",
    "\n",
    "        # derive the learning rate multiplier based on the ending\n",
    "        # learning rate, starting learning rate, and total number of\n",
    "        # batch updates\n",
    "        self.lrMult = (endLR / startLR) ** (1.0 / numBatchUpdates)\n",
    "\n",
    "        # create a temporary file path for the model weights and\n",
    "        # then save the weights (so we can reset the weights when we\n",
    "        # are done)\n",
    "        self.weightsFile = tempfile.mkstemp()[1]\n",
    "        self.model.save_weights(self.weightsFile)\n",
    "\n",
    "        # grab the *original* learning rate (so we can reset it\n",
    "        # later), and then set the *starting* learning rate\n",
    "        origLR = K.get_value(self.model.optimizer.lr)\n",
    "        K.set_value(self.model.optimizer.lr, startLR)\n",
    "\n",
    "        # construct a callback that will be called at the end of each\n",
    "        # batch, enabling us to increase our learning rate as training\n",
    "        # progresses\n",
    "        callback = LambdaCallback(on_batch_end=lambda batch, logs:\n",
    "            self.on_batch_end(batch, logs))\n",
    "\n",
    "        # check to see if we are using a data iterator\n",
    "        if useGen:\n",
    "            self.model.fit_generator(\n",
    "                trainData,\n",
    "                steps_per_epoch=stepsPerEpoch,\n",
    "                epochs=epochs,\n",
    "                verbose=verbose,\n",
    "                callbacks=[callback])\n",
    "\n",
    "        # otherwise, our entire training data is already in memory\n",
    "        else:\n",
    "            # train our model using Keras' fit method\n",
    "            self.model.fit(\n",
    "                trainData[0], trainData[1],\n",
    "                batch_size=batchSize,\n",
    "                epochs=epochs,\n",
    "                callbacks=[callback],\n",
    "                verbose=verbose)\n",
    "\n",
    "        # restore the original model weights and learning rate\n",
    "        self.model.load_weights(self.weightsFile)\n",
    "        K.set_value(self.model.optimizer.lr, origLR)\n",
    "\n",
    "    def plot_loss(self, skipBegin=10, skipEnd=1, title=\"\"):\n",
    "        # grab the learning rate and losses values to plot\n",
    "        lrs = self.lrs[skipBegin:-skipEnd]\n",
    "        losses = self.losses[skipBegin:-skipEnd]\n",
    "\n",
    "        # plot the learning rate vs. loss\n",
    "        plt.plot(lrs, losses)\n",
    "        plt.xscale(\"log\")\n",
    "        plt.xlabel(\"Learning Rate (Log Scale)\")\n",
    "        plt.ylabel(\"Loss\")\n",
    "\n",
    "        # if the title is not empty, add it to the plot\n",
    "        if title != \"\":\n",
    "            plt.title(title)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 516
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 30812,
     "status": "ok",
     "timestamp": 1574528606966,
     "user": {
      "displayName": "MIZUHIRO SUZUKI",
      "photoUrl": "",
      "userId": "11994014812088599130"
     },
     "user_tz": 360
    },
    "id": "Hm10WFcgjE6F",
    "outputId": "e5b35b83-eb63-416c-d24b-44e3991fc22b",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:203: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2041: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define a MLP for numerical variables\n",
    "model_mlp = Sequential()\n",
    "model_mlp.add(Dense(512, input_dim = total_num_var, activation = 'relu'))\n",
    "model_mlp.add(BatchNormalization())\n",
    "model_mlp.add(Dropout(0.5))\n",
    "model_mlp.add(Dense(256, activation = 'relu'))\n",
    "model_mlp.add(BatchNormalization())\n",
    "model_mlp.add(Dropout(0.5))\n",
    "model_mlp.add(Dense(128, activation = 'relu'))\n",
    "model_mlp.add(BatchNormalization())\n",
    "model_mlp.add(Dropout(0.5))\n",
    "model_mlp.add(Dense(64, activation = 'relu'))\n",
    "model_mlp.add(BatchNormalization())\n",
    "model_mlp.add(Dropout(0.5))\n",
    "\n",
    "# Define a CNN for image data\n",
    "inputs = Input(shape = (IMG_HEIGHT, IMG_WIDTH, 3))\n",
    "x = inputs\n",
    "\n",
    "filters = (64, 128, 256, 512)\n",
    "for (i, f) in enumerate(filters):\n",
    "  x = Conv2D(f, (3, 3), activation = 'relu', padding = 'same')(x)\n",
    "  x = BatchNormalization(axis = -1)(x)\n",
    "  x = Conv2D(f, (3, 3), activation = 'relu', padding = 'same')(x)\n",
    "  x = BatchNormalization(axis = -1)(x)\n",
    "  x = MaxPooling2D(pool_size = (2, 2))(x)\n",
    "  x = Dropout(0.2)(x)\n",
    "\n",
    "x = Flatten()(x)\n",
    "x = Dense(256, activation = 'relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "\n",
    "x = Dense(128, activation = 'relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "\n",
    "x = Dense(128, activation = 'relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "\n",
    "model_cnn = Model(inputs, x)\n",
    "\n",
    "combined_input = concatenate([model_cnn.output, model_mlp.output])\n",
    "\n",
    "x = Dense(256, activation = 'relu')(combined_input)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(256, activation = 'relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(256, activation = 'relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(5, activation = 'softmax')(x)\n",
    "\n",
    "model = Model(inputs = [model_cnn.input, model_mlp.input], outputs = x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "collapsed": true,
    "executionInfo": {
     "elapsed": 30765,
     "status": "ok",
     "timestamp": 1574528606968,
     "user": {
      "displayName": "MIZUHIRO SUZUKI",
      "photoUrl": "",
      "userId": "11994014812088599130"
     },
     "user_tz": 360
    },
    "id": "NHAWvd66uc2d",
    "outputId": "c73339b5-8895-4000-b57b-cbee6442636e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 224, 224, 64) 1792        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 224, 224, 64) 256         conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 224, 224, 64) 36928       batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 224, 224, 64) 256         conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 112, 112, 64) 0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 112, 112, 64) 0           max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 112, 112, 128 73856       dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 112, 112, 128 512         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 112, 112, 128 147584      batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 112, 112, 128 512         conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 56, 56, 128)  0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 56, 56, 128)  0           max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 56, 56, 256)  295168      dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 56, 56, 256)  1024        conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 56, 56, 256)  590080      batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 56, 56, 256)  1024        conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 28, 28, 256)  0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 28, 28, 256)  0           max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 28, 28, 512)  1180160     dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 28, 28, 512)  2048        conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 28, 28, 512)  2359808     batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 28, 28, 512)  2048        conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_1_input (InputLayer)      (None, 33)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 14, 14, 512)  0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 512)          17408       dense_1_input[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 14, 14, 512)  0           max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 512)          2048        dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 100352)       0           dropout_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 256)          25690368    flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 256)          131328      dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 256)          1024        dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 256)          1024        dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)             (None, 256)          0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 256)          0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 128)          32896       dropout_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 128)          32896       dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 128)          512         dense_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 128)          512         dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_10 (Dropout)            (None, 128)          0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 128)          0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 128)          16512       dropout_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 64)           8256        dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 128)          512         dense_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 64)           256         dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_11 (Dropout)            (None, 128)          0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 64)           0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 192)          0           dropout_11[0][0]                 \n",
      "                                                                 dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 256)          49408       concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 256)          1024        dense_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_12 (Dropout)            (None, 256)          0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 256)          65792       dropout_12[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 256)          1024        dense_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_13 (Dropout)            (None, 256)          0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Dense)                (None, 256)          65792       dropout_13[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 256)          1024        dense_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_14 (Dropout)            (None, 256)          0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_11 (Dense)                (None, 5)            1285        dropout_14[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 30,813,957\n",
      "Trainable params: 30,805,637\n",
      "Non-trainable params: 8,320\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "opt = Adam(lr = 1e-10)\n",
    "model.compile(optimizer = opt,\n",
    "              loss = 'categorical_crossentropy',\n",
    "              metrics = ['accuracy'])\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 572
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1515589,
     "status": "ok",
     "timestamp": 1574530091843,
     "user": {
      "displayName": "MIZUHIRO SUZUKI",
      "photoUrl": "",
      "userId": "11994014812088599130"
     },
     "user_tz": 360
    },
    "id": "EdT3E6d6m5ZC",
    "outputId": "6726cd09-f229-459b-b8e0-a5b055e0d39f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n",
      "Epoch 1/5\n",
      "232/232 [==============================] - 345s 1s/step - loss: 2.7132 - acc: 0.2007\n",
      "Epoch 2/5\n",
      "232/232 [==============================] - 323s 1s/step - loss: 2.7121 - acc: 0.1981\n",
      "Epoch 3/5\n",
      "232/232 [==============================] - 323s 1s/step - loss: 2.6108 - acc: 0.2073\n",
      "Epoch 4/5\n",
      "232/232 [==============================] - 322s 1s/step - loss: 1.5438 - acc: 0.4450\n",
      "Epoch 5/5\n",
      "119/232 [==============>...............] - ETA: 2:35 - loss: 3.6836 - acc: 0.5039"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEKCAYAAAAfGVI8AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nFxstioRVAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "lrf = LearningRateFinder(model)\n",
    "lrf.find(\n",
    "  train_data_generator,\n",
    "  1e-10, 1e+1,\n",
    "  stepsPerEpoch = total_train // batch_size,\n",
    "  batchSize = batch_size,\n",
    "  epochs = 5)\n",
    "\n",
    "# plot the loss for the various learning rates and save the\n",
    "# resulting plot to disk\n",
    "lrf.plot_loss()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AC1DJALR2HsB"
   },
   "source": [
    "### Retrain model with CLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 970,
     "status": "ok",
     "timestamp": 1574531884496,
     "user": {
      "displayName": "MIZUHIRO SUZUKI",
      "photoUrl": "",
      "userId": "11994014812088599130"
     },
     "user_tz": 360
    },
    "id": "ovGpC7fh2fYd",
    "outputId": "35d4da21-dd6d-4307-c885-e2569f8e9cde"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:107: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4iWMt-pyC0f9"
   },
   "outputs": [],
   "source": [
    "class CyclicLR(Callback):\n",
    "    \"\"\"This callback implements a cyclical learning rate policy (CLR).\n",
    "    The method cycles the learning rate between two boundaries with\n",
    "    some constant frequency, as detailed in this paper (https://arxiv.org/abs/1506.01186).\n",
    "    The amplitude of the cycle can be scaled on a per-iteration or \n",
    "    per-cycle basis.\n",
    "    This class has three built-in policies, as put forth in the paper.\n",
    "    \"triangular\":\n",
    "        A basic triangular cycle w/ no amplitude scaling.\n",
    "    \"triangular2\":\n",
    "        A basic triangular cycle that scales initial amplitude by half each cycle.\n",
    "    \"exp_range\":\n",
    "        A cycle that scales initial amplitude by gamma**(cycle iterations) at each \n",
    "        cycle iteration.\n",
    "    For more detail, please see paper.\n",
    "    \n",
    "    # Example\n",
    "        ```python\n",
    "            clr = CyclicLR(base_lr=0.001, max_lr=0.006,\n",
    "                                step_size=2000., mode='triangular')\n",
    "            model.fit(X_train, Y_train, callbacks=[clr])\n",
    "        ```\n",
    "    \n",
    "    Class also supports custom scaling functions:\n",
    "        ```python\n",
    "            clr_fn = lambda x: 0.5*(1+np.sin(x*np.pi/2.))\n",
    "            clr = CyclicLR(base_lr=0.001, max_lr=0.006,\n",
    "                                step_size=2000., scale_fn=clr_fn,\n",
    "                                scale_mode='cycle')\n",
    "            model.fit(X_train, Y_train, callbacks=[clr])\n",
    "        ```    \n",
    "    # Arguments\n",
    "        base_lr: initial learning rate which is the\n",
    "            lower boundary in the cycle.\n",
    "        max_lr: upper boundary in the cycle. Functionally,\n",
    "            it defines the cycle amplitude (max_lr - base_lr).\n",
    "            The lr at any cycle is the sum of base_lr\n",
    "            and some scaling of the amplitude; therefore \n",
    "            max_lr may not actually be reached depending on\n",
    "            scaling function.\n",
    "        step_size: number of training iterations per\n",
    "            half cycle. Authors suggest setting step_size\n",
    "            2-8 x training iterations in epoch.\n",
    "        mode: one of {triangular, triangular2, exp_range}.\n",
    "            Default 'triangular'.\n",
    "            Values correspond to policies detailed above.\n",
    "            If scale_fn is not None, this argument is ignored.\n",
    "        gamma: constant in 'exp_range' scaling function:\n",
    "            gamma**(cycle iterations)\n",
    "        scale_fn: Custom scaling policy defined by a single\n",
    "            argument lambda function, where \n",
    "            0 <= scale_fn(x) <= 1 for all x >= 0.\n",
    "            mode paramater is ignored \n",
    "        scale_mode: {'cycle', 'iterations'}.\n",
    "            Defines whether scale_fn is evaluated on \n",
    "            cycle number or cycle iterations (training\n",
    "            iterations since start of cycle). Default is 'cycle'.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, base_lr=0.001, max_lr=0.006, step_size=2000., mode='triangular',\n",
    "                 gamma=1., scale_fn=None, scale_mode='cycle'):\n",
    "        super(CyclicLR, self).__init__()\n",
    "\n",
    "        self.base_lr = base_lr\n",
    "        self.max_lr = max_lr\n",
    "        self.step_size = step_size\n",
    "        self.mode = mode\n",
    "        self.gamma = gamma\n",
    "        if scale_fn == None:\n",
    "            if self.mode == 'triangular':\n",
    "                self.scale_fn = lambda x: 1.\n",
    "                self.scale_mode = 'cycle'\n",
    "            elif self.mode == 'triangular2':\n",
    "                self.scale_fn = lambda x: 1/(2.**(x-1))\n",
    "                self.scale_mode = 'cycle'\n",
    "            elif self.mode == 'exp_range':\n",
    "                self.scale_fn = lambda x: gamma**(x)\n",
    "                self.scale_mode = 'iterations'\n",
    "        else:\n",
    "            self.scale_fn = scale_fn\n",
    "            self.scale_mode = scale_mode\n",
    "        self.clr_iterations = 0.\n",
    "        self.trn_iterations = 0.\n",
    "        self.history = {}\n",
    "\n",
    "        self._reset()\n",
    "\n",
    "    def _reset(self, new_base_lr=None, new_max_lr=None,\n",
    "               new_step_size=None):\n",
    "        \"\"\"Resets cycle iterations.\n",
    "        Optional boundary/step size adjustment.\n",
    "        \"\"\"\n",
    "        if new_base_lr != None:\n",
    "            self.base_lr = new_base_lr\n",
    "        if new_max_lr != None:\n",
    "            self.max_lr = new_max_lr\n",
    "        if new_step_size != None:\n",
    "            self.step_size = new_step_size\n",
    "        self.clr_iterations = 0.\n",
    "        \n",
    "    def clr(self):\n",
    "        cycle = np.floor(1+self.clr_iterations/(2*self.step_size))\n",
    "        x = np.abs(self.clr_iterations/self.step_size - 2*cycle + 1)\n",
    "        if self.scale_mode == 'cycle':\n",
    "            return self.base_lr + (self.max_lr-self.base_lr)*np.maximum(0, (1-x))*self.scale_fn(cycle)\n",
    "        else:\n",
    "            return self.base_lr + (self.max_lr-self.base_lr)*np.maximum(0, (1-x))*self.scale_fn(self.clr_iterations)\n",
    "        \n",
    "    def on_train_begin(self, logs={}):\n",
    "        logs = logs or {}\n",
    "\n",
    "        if self.clr_iterations == 0:\n",
    "            K.set_value(self.model.optimizer.lr, self.base_lr)\n",
    "        else:\n",
    "            K.set_value(self.model.optimizer.lr, self.clr())        \n",
    "            \n",
    "    def on_batch_end(self, epoch, logs=None):\n",
    "        \n",
    "        logs = logs or {}\n",
    "        self.trn_iterations += 1\n",
    "        self.clr_iterations += 1\n",
    "\n",
    "        self.history.setdefault('lr', []).append(K.get_value(self.model.optimizer.lr))\n",
    "        self.history.setdefault('iterations', []).append(self.trn_iterations)\n",
    "\n",
    "        for k, v in logs.items():\n",
    "            self.history.setdefault(k, []).append(v)\n",
    "        \n",
    "        K.set_value(self.model.optimizer.lr, self.clr())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hVKMJ1pAd3hi"
   },
   "source": [
    "### Retrain model with CLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BZkxG0dSd3hk"
   },
   "outputs": [],
   "source": [
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HRIRQ5YweMZA"
   },
   "outputs": [],
   "source": [
    "# Define a MLP for numerical variables\n",
    "model_mlp = Sequential()\n",
    "model_mlp.add(Dense(512, input_dim = total_num_var, activation = 'relu'))\n",
    "model_mlp.add(BatchNormalization())\n",
    "model_mlp.add(Dropout(0.5))\n",
    "model_mlp.add(Dense(256, activation = 'relu'))\n",
    "model_mlp.add(BatchNormalization())\n",
    "model_mlp.add(Dropout(0.5))\n",
    "model_mlp.add(Dense(128, activation = 'relu'))\n",
    "model_mlp.add(BatchNormalization())\n",
    "model_mlp.add(Dropout(0.5))\n",
    "model_mlp.add(Dense(64, activation = 'relu'))\n",
    "model_mlp.add(BatchNormalization())\n",
    "model_mlp.add(Dropout(0.5))\n",
    "\n",
    "# Define a CNN for image data\n",
    "inputs = Input(shape = (IMG_HEIGHT, IMG_WIDTH, 3))\n",
    "x = inputs\n",
    "\n",
    "filters = (64, 128, 256, 512)\n",
    "for (i, f) in enumerate(filters):\n",
    "  x = Conv2D(f, (3, 3), activation = 'relu', padding = 'same')(x)\n",
    "  x = BatchNormalization(axis = -1)(x)\n",
    "  x = Conv2D(f, (3, 3), activation = 'relu', padding = 'same')(x)\n",
    "  x = BatchNormalization(axis = -1)(x)\n",
    "  x = MaxPooling2D(pool_size = (2, 2))(x)\n",
    "  x = Dropout(0.2)(x)\n",
    "\n",
    "x = Flatten()(x)\n",
    "x = Dense(256, activation = 'relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "\n",
    "x = Dense(128, activation = 'relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "\n",
    "x = Dense(128, activation = 'relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "\n",
    "model_cnn = Model(inputs, x)\n",
    "\n",
    "combined_input = concatenate([model_cnn.output, model_mlp.output])\n",
    "\n",
    "x = Dense(256, activation = 'relu')(combined_input)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(256, activation = 'relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(256, activation = 'relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(5, activation = 'softmax')(x)\n",
    "\n",
    "model = Model(inputs = [model_cnn.input, model_mlp.input], outputs = x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PUZfQVJ7d3hn"
   },
   "outputs": [],
   "source": [
    "opt = Adam(lr = 1e-4)\n",
    "\n",
    "model.compile(optimizer = opt,\n",
    "              loss = 'categorical_crossentropy',\n",
    "              metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qi0oO7Nsd3hq"
   },
   "outputs": [],
   "source": [
    "clr = CyclicLR(\n",
    "\tmode = 'triangular2',\n",
    "\tbase_lr = 1e-4,\n",
    "\tmax_lr = 1e-2,\n",
    "\tstep_size = 4 * (total_train // batch_size))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pS1YztR4d3ht"
   },
   "outputs": [],
   "source": [
    "checkpoint_path = os.path.join(path, 'model_cp/mixed_inputs_cnn/mixed_inputs_mask_cp.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vCmx6LBNd3hu"
   },
   "outputs": [],
   "source": [
    "# Create a callback that saves the model's weights\n",
    "cp_callback = ModelCheckpoint(\n",
    "    filepath = checkpoint_path, \n",
    "    verbose = 1, \n",
    "    monitor = 'val_loss',\n",
    "    mode = 'min',\n",
    "    save_best_only = True)\n",
    "\n",
    "# define an early stopping rule\n",
    "early_stopping_callback = EarlyStopping(monitor = 'val_loss',\n",
    "                                        mode = 'min',\n",
    "                                        verbose = 1,\n",
    "                                        patience = 10)\n",
    "\n",
    "# define class weights to account for imbalance in training data\n",
    "class_weights = class_weight.compute_class_weight('balanced',\n",
    "                                                 np.unique(train_label),\n",
    "                                                 train_label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "collapsed": true,
    "executionInfo": {
     "elapsed": 27007442,
     "status": "ok",
     "timestamp": 1574558910828,
     "user": {
      "displayName": "MIZUHIRO SUZUKI",
      "photoUrl": "",
      "userId": "11994014812088599130"
     },
     "user_tz": 360
    },
    "id": "K9C1fuuLd3hw",
    "outputId": "a4795699-ebf2-45d4-f348-7f29c2f681a9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "232/232 [==============================] - 381s 2s/step - loss: 1.8920 - acc: 0.3526 - val_loss: 1.0134 - val_acc: 0.6196\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.01340, saving model to /content/drive/My Drive/stac/model_cp/mixed_inputs_cnn/mixed_inputs_mask_cp_20191123.h5\n",
      "Epoch 2/100\n",
      "232/232 [==============================] - 363s 2s/step - loss: 1.0534 - acc: 0.5928 - val_loss: 1.0543 - val_acc: 0.5628\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 1.01340\n",
      "Epoch 3/100\n",
      "232/232 [==============================] - 362s 2s/step - loss: 0.9614 - acc: 0.6337 - val_loss: 1.0902 - val_acc: 0.5384\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1.01340\n",
      "Epoch 4/100\n",
      "232/232 [==============================] - 363s 2s/step - loss: 0.8918 - acc: 0.6642 - val_loss: 1.2246 - val_acc: 0.5146\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1.01340\n",
      "Epoch 5/100\n",
      "232/232 [==============================] - 362s 2s/step - loss: 0.8277 - acc: 0.6877 - val_loss: 0.7750 - val_acc: 0.6799\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.01340 to 0.77498, saving model to /content/drive/My Drive/stac/model_cp/mixed_inputs_cnn/mixed_inputs_mask_cp_20191123.h5\n",
      "Epoch 6/100\n",
      "232/232 [==============================] - 362s 2s/step - loss: 0.7844 - acc: 0.7063 - val_loss: 0.6994 - val_acc: 0.7330\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.77498 to 0.69941, saving model to /content/drive/My Drive/stac/model_cp/mixed_inputs_cnn/mixed_inputs_mask_cp_20191123.h5\n",
      "Epoch 7/100\n",
      "232/232 [==============================] - 363s 2s/step - loss: 0.7312 - acc: 0.7232 - val_loss: 0.6589 - val_acc: 0.7514\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.69941 to 0.65888, saving model to /content/drive/My Drive/stac/model_cp/mixed_inputs_cnn/mixed_inputs_mask_cp_20191123.h5\n",
      "Epoch 8/100\n",
      "232/232 [==============================] - 363s 2s/step - loss: 0.7015 - acc: 0.7416 - val_loss: 0.5922 - val_acc: 0.7830\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.65888 to 0.59223, saving model to /content/drive/My Drive/stac/model_cp/mixed_inputs_cnn/mixed_inputs_mask_cp_20191123.h5\n",
      "Epoch 9/100\n",
      "232/232 [==============================] - 363s 2s/step - loss: 0.6980 - acc: 0.7399 - val_loss: 0.6666 - val_acc: 0.7373\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.59223\n",
      "Epoch 10/100\n",
      "232/232 [==============================] - 362s 2s/step - loss: 0.6876 - acc: 0.7493 - val_loss: 0.6378 - val_acc: 0.7549\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.59223\n",
      "Epoch 11/100\n",
      "232/232 [==============================] - 361s 2s/step - loss: 0.6973 - acc: 0.7336 - val_loss: 0.6929 - val_acc: 0.7392\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.59223\n",
      "Epoch 12/100\n",
      "232/232 [==============================] - 361s 2s/step - loss: 0.7247 - acc: 0.7325 - val_loss: 0.7220 - val_acc: 0.7243\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.59223\n",
      "Epoch 13/100\n",
      "232/232 [==============================] - 361s 2s/step - loss: 0.7126 - acc: 0.7338 - val_loss: 0.6963 - val_acc: 0.7300\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.59223\n",
      "Epoch 14/100\n",
      "232/232 [==============================] - 362s 2s/step - loss: 0.6889 - acc: 0.7477 - val_loss: 0.5925 - val_acc: 0.7752\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.59223\n",
      "Epoch 15/100\n",
      "232/232 [==============================] - 362s 2s/step - loss: 0.6540 - acc: 0.7565 - val_loss: 0.6045 - val_acc: 0.7703\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.59223\n",
      "Epoch 16/100\n",
      "232/232 [==============================] - 363s 2s/step - loss: 0.6481 - acc: 0.7588 - val_loss: 0.5466 - val_acc: 0.7914\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.59223 to 0.54661, saving model to /content/drive/My Drive/stac/model_cp/mixed_inputs_cnn/mixed_inputs_mask_cp_20191123.h5\n",
      "Epoch 17/100\n",
      "232/232 [==============================] - 365s 2s/step - loss: 0.6232 - acc: 0.7665 - val_loss: 0.6095 - val_acc: 0.7565\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.54661\n",
      "Epoch 18/100\n",
      "232/232 [==============================] - 364s 2s/step - loss: 0.6397 - acc: 0.7629 - val_loss: 0.5746 - val_acc: 0.7735\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.54661\n",
      "Epoch 19/100\n",
      "232/232 [==============================] - 367s 2s/step - loss: 0.6455 - acc: 0.7597 - val_loss: 0.5833 - val_acc: 0.7700\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.54661\n",
      "Epoch 20/100\n",
      "232/232 [==============================] - 364s 2s/step - loss: 0.6580 - acc: 0.7538 - val_loss: 0.5832 - val_acc: 0.7787\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.54661\n",
      "Epoch 21/100\n",
      "232/232 [==============================] - 365s 2s/step - loss: 0.6556 - acc: 0.7569 - val_loss: 0.5577 - val_acc: 0.7825\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.54661\n",
      "Epoch 22/100\n",
      "232/232 [==============================] - 363s 2s/step - loss: 0.6441 - acc: 0.7597 - val_loss: 0.5601 - val_acc: 0.7890\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.54661\n",
      "Epoch 23/100\n",
      "232/232 [==============================] - 363s 2s/step - loss: 0.6299 - acc: 0.7591 - val_loss: 0.5423 - val_acc: 0.7895\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.54661 to 0.54228, saving model to /content/drive/My Drive/stac/model_cp/mixed_inputs_cnn/mixed_inputs_mask_cp_20191123.h5\n",
      "Epoch 24/100\n",
      "232/232 [==============================] - 363s 2s/step - loss: 0.6060 - acc: 0.7713 - val_loss: 0.5146 - val_acc: 0.8120\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.54228 to 0.51459, saving model to /content/drive/My Drive/stac/model_cp/mixed_inputs_cnn/mixed_inputs_mask_cp_20191123.h5\n",
      "Epoch 25/100\n",
      "232/232 [==============================] - 363s 2s/step - loss: 0.5989 - acc: 0.7714 - val_loss: 0.5422 - val_acc: 0.7952\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.51459\n",
      "Epoch 26/100\n",
      "232/232 [==============================] - 362s 2s/step - loss: 0.6038 - acc: 0.7718 - val_loss: 0.5472 - val_acc: 0.7938\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.51459\n",
      "Epoch 27/100\n",
      "232/232 [==============================] - 363s 2s/step - loss: 0.6103 - acc: 0.7698 - val_loss: 0.5363 - val_acc: 0.7892\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.51459\n",
      "Epoch 28/100\n",
      "232/232 [==============================] - 364s 2s/step - loss: 0.6243 - acc: 0.7634 - val_loss: 0.5857 - val_acc: 0.7779\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.51459\n",
      "Epoch 29/100\n",
      "232/232 [==============================] - 361s 2s/step - loss: 0.6286 - acc: 0.7681 - val_loss: 0.6525 - val_acc: 0.7492\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.51459\n",
      "Epoch 30/100\n",
      "232/232 [==============================] - 361s 2s/step - loss: 0.6078 - acc: 0.7689 - val_loss: 0.5383 - val_acc: 0.7992\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.51459\n",
      "Epoch 31/100\n",
      "232/232 [==============================] - 361s 2s/step - loss: 0.6042 - acc: 0.7708 - val_loss: 0.5049 - val_acc: 0.8060\n",
      "\n",
      "Epoch 00031: val_loss improved from 0.51459 to 0.50490, saving model to /content/drive/My Drive/stac/model_cp/mixed_inputs_cnn/mixed_inputs_mask_cp_20191123.h5\n",
      "Epoch 32/100\n",
      "232/232 [==============================] - 360s 2s/step - loss: 0.5757 - acc: 0.7881 - val_loss: 0.5036 - val_acc: 0.8090\n",
      "\n",
      "Epoch 00032: val_loss improved from 0.50490 to 0.50361, saving model to /content/drive/My Drive/stac/model_cp/mixed_inputs_cnn/mixed_inputs_mask_cp_20191123.h5\n",
      "Epoch 33/100\n",
      "232/232 [==============================] - 361s 2s/step - loss: 0.5795 - acc: 0.7829 - val_loss: 0.5733 - val_acc: 0.7733\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.50361\n",
      "Epoch 34/100\n",
      "232/232 [==============================] - 360s 2s/step - loss: 0.5795 - acc: 0.7839 - val_loss: 0.5710 - val_acc: 0.7735\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.50361\n",
      "Epoch 35/100\n",
      "232/232 [==============================] - 361s 2s/step - loss: 0.5954 - acc: 0.7789 - val_loss: 0.5243 - val_acc: 0.8028\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.50361\n",
      "Epoch 36/100\n",
      "232/232 [==============================] - 366s 2s/step - loss: 0.5937 - acc: 0.7763 - val_loss: 0.5342 - val_acc: 0.7903\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.50361\n",
      "Epoch 37/100\n",
      "232/232 [==============================] - 367s 2s/step - loss: 0.5912 - acc: 0.7786 - val_loss: 0.5324 - val_acc: 0.7949\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.50361\n",
      "Epoch 38/100\n",
      "232/232 [==============================] - 368s 2s/step - loss: 0.5830 - acc: 0.7812 - val_loss: 0.4964 - val_acc: 0.8182\n",
      "\n",
      "Epoch 00038: val_loss improved from 0.50361 to 0.49641, saving model to /content/drive/My Drive/stac/model_cp/mixed_inputs_cnn/mixed_inputs_mask_cp_20191123.h5\n",
      "Epoch 39/100\n",
      "232/232 [==============================] - 367s 2s/step - loss: 0.5697 - acc: 0.7850 - val_loss: 0.5769 - val_acc: 0.7819\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.49641\n",
      "Epoch 40/100\n",
      "232/232 [==============================] - 368s 2s/step - loss: 0.5580 - acc: 0.7862 - val_loss: 0.4823 - val_acc: 0.8298\n",
      "\n",
      "Epoch 00040: val_loss improved from 0.49641 to 0.48232, saving model to /content/drive/My Drive/stac/model_cp/mixed_inputs_cnn/mixed_inputs_mask_cp_20191123.h5\n",
      "Epoch 41/100\n",
      "232/232 [==============================] - 369s 2s/step - loss: 0.5518 - acc: 0.7936 - val_loss: 0.4919 - val_acc: 0.8139\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.48232\n",
      "Epoch 42/100\n",
      "232/232 [==============================] - 369s 2s/step - loss: 0.5592 - acc: 0.7903 - val_loss: 0.5230 - val_acc: 0.8063\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.48232\n",
      "Epoch 43/100\n",
      "232/232 [==============================] - 369s 2s/step - loss: 0.5732 - acc: 0.7803 - val_loss: 0.5183 - val_acc: 0.8017\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.48232\n",
      "Epoch 44/100\n",
      "232/232 [==============================] - 369s 2s/step - loss: 0.5523 - acc: 0.7892 - val_loss: 0.6022 - val_acc: 0.7771\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.48232\n",
      "Epoch 45/100\n",
      "232/232 [==============================] - 367s 2s/step - loss: 0.5644 - acc: 0.7870 - val_loss: 0.5051 - val_acc: 0.8076\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.48232\n",
      "Epoch 46/100\n",
      "232/232 [==============================] - 366s 2s/step - loss: 0.5693 - acc: 0.7839 - val_loss: 0.4927 - val_acc: 0.8155\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.48232\n",
      "Epoch 47/100\n",
      "232/232 [==============================] - 366s 2s/step - loss: 0.5489 - acc: 0.7932 - val_loss: 0.5021 - val_acc: 0.8157\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.48232\n",
      "Epoch 48/100\n",
      "232/232 [==============================] - 366s 2s/step - loss: 0.5433 - acc: 0.7962 - val_loss: 0.4776 - val_acc: 0.8201\n",
      "\n",
      "Epoch 00048: val_loss improved from 0.48232 to 0.47758, saving model to /content/drive/My Drive/stac/model_cp/mixed_inputs_cnn/mixed_inputs_mask_cp_20191123.h5\n",
      "Epoch 49/100\n",
      "232/232 [==============================] - 366s 2s/step - loss: 0.5350 - acc: 0.7993 - val_loss: 0.4678 - val_acc: 0.8301\n",
      "\n",
      "Epoch 00049: val_loss improved from 0.47758 to 0.46777, saving model to /content/drive/My Drive/stac/model_cp/mixed_inputs_cnn/mixed_inputs_mask_cp_20191123.h5\n",
      "Epoch 50/100\n",
      "232/232 [==============================] - 385s 2s/step - loss: 0.5328 - acc: 0.7977 - val_loss: 0.4841 - val_acc: 0.8212\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.46777\n",
      "Epoch 51/100\n",
      "232/232 [==============================] - 368s 2s/step - loss: 0.5355 - acc: 0.7967 - val_loss: 0.4858 - val_acc: 0.8128\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.46777\n",
      "Epoch 52/100\n",
      "232/232 [==============================] - 365s 2s/step - loss: 0.5478 - acc: 0.7933 - val_loss: 0.4919 - val_acc: 0.8144\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 0.46777\n",
      "Epoch 53/100\n",
      "232/232 [==============================] - 365s 2s/step - loss: 0.5398 - acc: 0.7967 - val_loss: 0.5959 - val_acc: 0.7622\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 0.46777\n",
      "Epoch 54/100\n",
      "232/232 [==============================] - 366s 2s/step - loss: 0.5273 - acc: 0.7997 - val_loss: 0.4971 - val_acc: 0.8120\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 0.46777\n",
      "Epoch 55/100\n",
      "232/232 [==============================] - 367s 2s/step - loss: 0.5278 - acc: 0.7998 - val_loss: 0.5001 - val_acc: 0.8160\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 0.46777\n",
      "Epoch 56/100\n",
      "232/232 [==============================] - 366s 2s/step - loss: 0.5217 - acc: 0.8021 - val_loss: 0.4673 - val_acc: 0.8176\n",
      "\n",
      "Epoch 00056: val_loss improved from 0.46777 to 0.46733, saving model to /content/drive/My Drive/stac/model_cp/mixed_inputs_cnn/mixed_inputs_mask_cp_20191123.h5\n",
      "Epoch 57/100\n",
      "232/232 [==============================] - 362s 2s/step - loss: 0.5312 - acc: 0.7991 - val_loss: 0.4713 - val_acc: 0.8198\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 0.46733\n",
      "Epoch 58/100\n",
      "232/232 [==============================] - 360s 2s/step - loss: 0.5299 - acc: 0.8004 - val_loss: 0.4994 - val_acc: 0.8171\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 0.46733\n",
      "Epoch 59/100\n",
      "232/232 [==============================] - 360s 2s/step - loss: 0.5221 - acc: 0.8030 - val_loss: 0.4569 - val_acc: 0.8333\n",
      "\n",
      "Epoch 00059: val_loss improved from 0.46733 to 0.45687, saving model to /content/drive/My Drive/stac/model_cp/mixed_inputs_cnn/mixed_inputs_mask_cp_20191123.h5\n",
      "Epoch 60/100\n",
      "232/232 [==============================] - 360s 2s/step - loss: 0.5285 - acc: 0.7989 - val_loss: 0.5087 - val_acc: 0.8074\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 0.45687\n",
      "Epoch 61/100\n",
      "232/232 [==============================] - 360s 2s/step - loss: 0.5203 - acc: 0.8072 - val_loss: 0.6324 - val_acc: 0.7668\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 0.45687\n",
      "Epoch 62/100\n",
      "232/232 [==============================] - 360s 2s/step - loss: 0.5101 - acc: 0.8090 - val_loss: 0.4602 - val_acc: 0.8279\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.45687\n",
      "Epoch 63/100\n",
      "232/232 [==============================] - 361s 2s/step - loss: 0.5069 - acc: 0.8048 - val_loss: 0.4912 - val_acc: 0.8174\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.45687\n",
      "Epoch 64/100\n",
      "232/232 [==============================] - 362s 2s/step - loss: 0.5024 - acc: 0.8120 - val_loss: 0.4530 - val_acc: 0.8260\n",
      "\n",
      "Epoch 00064: val_loss improved from 0.45687 to 0.45304, saving model to /content/drive/My Drive/stac/model_cp/mixed_inputs_cnn/mixed_inputs_mask_cp_20191123.h5\n",
      "Epoch 65/100\n",
      "232/232 [==============================] - 362s 2s/step - loss: 0.5078 - acc: 0.8072 - val_loss: 0.4733 - val_acc: 0.8141\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 0.45304\n",
      "Epoch 66/100\n",
      "232/232 [==============================] - 361s 2s/step - loss: 0.5015 - acc: 0.8075 - val_loss: 0.4778 - val_acc: 0.8233\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 0.45304\n",
      "Epoch 67/100\n",
      "232/232 [==============================] - 363s 2s/step - loss: 0.5046 - acc: 0.8103 - val_loss: 0.4666 - val_acc: 0.8285\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 0.45304\n",
      "Epoch 68/100\n",
      "232/232 [==============================] - 363s 2s/step - loss: 0.5144 - acc: 0.8061 - val_loss: 0.4591 - val_acc: 0.8287\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 0.45304\n",
      "Epoch 69/100\n",
      "232/232 [==============================] - 364s 2s/step - loss: 0.5098 - acc: 0.8089 - val_loss: 0.4633 - val_acc: 0.8244\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 0.45304\n",
      "Epoch 70/100\n",
      "232/232 [==============================] - 364s 2s/step - loss: 0.5022 - acc: 0.8136 - val_loss: 0.4697 - val_acc: 0.8228\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 0.45304\n",
      "Epoch 71/100\n",
      "232/232 [==============================] - 365s 2s/step - loss: 0.4993 - acc: 0.8102 - val_loss: 0.5102 - val_acc: 0.8079\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 0.45304\n",
      "Epoch 72/100\n",
      "232/232 [==============================] - 365s 2s/step - loss: 0.4944 - acc: 0.8181 - val_loss: 0.4570 - val_acc: 0.8282\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 0.45304\n",
      "Epoch 73/100\n",
      "232/232 [==============================] - 364s 2s/step - loss: 0.4882 - acc: 0.8190 - val_loss: 0.4867 - val_acc: 0.8179\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 0.45304\n",
      "Epoch 74/100\n",
      "232/232 [==============================] - 363s 2s/step - loss: 0.4933 - acc: 0.8140 - val_loss: 0.4826 - val_acc: 0.8185\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 0.45304\n",
      "Epoch 00074: early stopping\n"
     ]
    }
   ],
   "source": [
    "epochs = 100\n",
    "\n",
    "history = model.fit_generator(\n",
    "    train_data_generator,\n",
    "    steps_per_epoch = total_train // batch_size,\n",
    "    epochs = epochs,\n",
    "    validation_data = validation_data_generator,\n",
    "    validation_steps = total_valid // batch_size,\n",
    "    callbacks = [clr, early_stopping_callback, cp_callback],\n",
    "    class_weight = class_weights\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SPYTy6hy2Fgf"
   },
   "source": [
    "## Prediction for test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EsB5cizlpct9"
   },
   "outputs": [],
   "source": [
    "datagen_test = ImageDataGenerator(rescale = 1./255,\n",
    "                                  shear_range=0.1,\n",
    "                                  zoom_range=0.1,\n",
    "                                  horizontal_flip=True,\n",
    "                                  vertical_flip=True,\n",
    "                                  rotation_range=10.,\n",
    "                                  width_shift_range = 0.1,\n",
    "                                  height_shift_range = 0.1,\n",
    "                                  featurewise_center = True)\n",
    "datagen_test.mean = [train_data.R_mean.mean() / 255, train_data.G_mean.mean() / 255, train_data.B_mean.mean() / 255]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 697
    },
    "colab_type": "code",
    "collapsed": true,
    "executionInfo": {
     "elapsed": 5130987,
     "status": "ok",
     "timestamp": 1574564920923,
     "user": {
      "displayName": "MIZUHIRO SUZUKI",
      "photoUrl": "",
      "userId": "11994014812088599130"
     },
     "user_tz": 360
    },
    "id": "dPhY2Kgwf5Qk",
    "outputId": "963e4307-53de-4e30-eb17-382235886921"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "153/153 [==============================] - 154s 1s/step\n",
      "1\n",
      "153/153 [==============================] - 150s 979ms/step\n",
      "2\n",
      "153/153 [==============================] - 149s 976ms/step\n",
      "3\n",
      "153/153 [==============================] - 150s 977ms/step\n",
      "4\n",
      "153/153 [==============================] - 149s 976ms/step\n",
      "5\n",
      "153/153 [==============================] - 149s 973ms/step\n",
      "6\n",
      "153/153 [==============================] - 148s 968ms/step\n",
      "7\n",
      "153/153 [==============================] - 148s 967ms/step\n",
      "8\n",
      "153/153 [==============================] - 149s 972ms/step\n",
      "9\n",
      "153/153 [==============================] - 151s 984ms/step\n",
      "10\n",
      "153/153 [==============================] - 149s 973ms/step\n",
      "11\n",
      "153/153 [==============================] - 151s 984ms/step\n",
      "12\n",
      "153/153 [==============================] - 151s 988ms/step\n",
      "13\n",
      "153/153 [==============================] - 151s 990ms/step\n",
      "14\n",
      "153/153 [==============================] - 151s 987ms/step\n",
      "15\n",
      "153/153 [==============================] - 151s 985ms/step\n",
      "16\n",
      "153/153 [==============================] - 152s 995ms/step\n",
      "17\n",
      "153/153 [==============================] - 152s 993ms/step\n",
      "18\n",
      "153/153 [==============================] - 152s 995ms/step\n",
      "19\n",
      "153/153 [==============================] - 152s 994ms/step\n"
     ]
    }
   ],
   "source": [
    "tta_steps = 20\n",
    "predictions = []\n",
    "\n",
    "for i in range(tta_steps):\n",
    "    print(i)\n",
    "    test_data_generator = custom_generator(test_image_file_list, test_data_csv, \n",
    "                                          lb_label, continuous_var_list, categorical_var_list, \n",
    "                                          minmaxscaler, lb_list, \n",
    "                                          batch_size, mode = 'eval', augment = datagen_test)\n",
    "    preds = model.predict_generator(test_data_generator, \n",
    "                                    steps = total_test // batch_size + 1,\n",
    "                                    verbose = 1)\n",
    "    predictions.append(preds)\n",
    "\n",
    "pred = np.mean(predictions, axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tiJm8xxurQAH"
   },
   "outputs": [],
   "source": [
    "pred_pd = pd.DataFrame({'id': test_data_csv.id})\n",
    "\n",
    "test_image_file_list = glob(os.path.join(path, 'image_mask/test/*.jpg'))\n",
    "pred_id_temp = [os.path.basename(test_image_file_list[i]).replace('.jpg', '') for i in range(total_test)]\n",
    "pred_pd_temp = pd.DataFrame({'id': pred_id_temp})\n",
    "pred_pd_temp['concrete_cement'] = pred[:, 0]\n",
    "pred_pd_temp['healthy_metal'] = pred[:, 1]\n",
    "pred_pd_temp['incomplete'] = pred[:, 2]\n",
    "pred_pd_temp['irregular_metal'] = pred[:, 3]\n",
    "pred_pd_temp['other'] = pred[:, 4]\n",
    "\n",
    "pred_pd = pd.merge(pred_pd, pred_pd_temp, on = 'id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "H23UGWdswFOQ"
   },
   "outputs": [],
   "source": [
    "pred_pd.to_csv(os.path.join(path, 'submission/mixed_inputs_mask.csv'), index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SPYTy6hy2Fgf"
   },
   "source": [
    "## Prediction for training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EsB5cizlpct9"
   },
   "outputs": [],
   "source": [
    "datagen_train = ImageDataGenerator(rescale = 1./255,\n",
    "                                  shear_range=0.1,\n",
    "                                  zoom_range=0.1,\n",
    "                                  horizontal_flip=True,\n",
    "                                  vertical_flip=True,\n",
    "                                  rotation_range=10.,\n",
    "                                  width_shift_range = 0.1,\n",
    "                                  height_shift_range = 0.1,\n",
    "                                  featurewise_center = True)\n",
    "datagen_train.mean = [train_data.R_mean.mean() / 255, train_data.G_mean.mean() / 255, train_data.B_mean.mean() / 255]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 697
    },
    "colab_type": "code",
    "collapsed": true,
    "executionInfo": {
     "elapsed": 5130987,
     "status": "ok",
     "timestamp": 1574564920923,
     "user": {
      "displayName": "MIZUHIRO SUZUKI",
      "photoUrl": "",
      "userId": "11994014812088599130"
     },
     "user_tz": 360
    },
    "id": "dPhY2Kgwf5Qk",
    "outputId": "963e4307-53de-4e30-eb17-382235886921"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "153/153 [==============================] - 154s 1s/step\n",
      "1\n",
      "153/153 [==============================] - 150s 979ms/step\n",
      "2\n",
      "153/153 [==============================] - 149s 976ms/step\n",
      "3\n",
      "153/153 [==============================] - 150s 977ms/step\n",
      "4\n",
      "153/153 [==============================] - 149s 976ms/step\n",
      "5\n",
      "153/153 [==============================] - 149s 973ms/step\n",
      "6\n",
      "153/153 [==============================] - 148s 968ms/step\n",
      "7\n",
      "153/153 [==============================] - 148s 967ms/step\n",
      "8\n",
      "153/153 [==============================] - 149s 972ms/step\n",
      "9\n",
      "153/153 [==============================] - 151s 984ms/step\n",
      "10\n",
      "153/153 [==============================] - 149s 973ms/step\n",
      "11\n",
      "153/153 [==============================] - 151s 984ms/step\n",
      "12\n",
      "153/153 [==============================] - 151s 988ms/step\n",
      "13\n",
      "153/153 [==============================] - 151s 990ms/step\n",
      "14\n",
      "153/153 [==============================] - 151s 987ms/step\n",
      "15\n",
      "153/153 [==============================] - 151s 985ms/step\n",
      "16\n",
      "153/153 [==============================] - 152s 995ms/step\n",
      "17\n",
      "153/153 [==============================] - 152s 993ms/step\n",
      "18\n",
      "153/153 [==============================] - 152s 995ms/step\n",
      "19\n",
      "153/153 [==============================] - 152s 994ms/step\n"
     ]
    }
   ],
   "source": [
    "tta_steps = 20\n",
    "predictions = []\n",
    "train_image_file_list = glob(os.path.join(path, 'image_mask/train/*.jpg'))\n",
    "total_train = len(train_image_file_list)\n",
    "\n",
    "for i in range(tta_steps):\n",
    "    print(i)\n",
    "    train_data_generator = custom_generator(train_image_file_list, train_data_csv, \n",
    "                                          lb_label, continuous_var_list, categorical_var_list, \n",
    "                                          minmaxscaler, lb_list, \n",
    "                                          batch_size, mode = 'eval', augment = datagen_train)\n",
    "    preds = model.predict_generator(train_data_generator, \n",
    "                                    steps = total_train // batch_size + 1,\n",
    "                                    verbose = 1)\n",
    "    predictions.append(preds)\n",
    "\n",
    "pred = np.mean(predictions, axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tiJm8xxurQAH"
   },
   "outputs": [],
   "source": [
    "pred_pd = pd.DataFrame({'id': train_data_csv.id})\n",
    "\n",
    "train_image_file_list = glob(os.path.join(path, 'image_mask/train/*.jpg'))\n",
    "pred_id_temp = [os.path.basename(train_image_file_list[i]).replace('.jpg', '') for i in range(total_train)]\n",
    "pred_pd_temp = pd.DataFrame({'id': pred_id_temp})\n",
    "pred_pd_temp['concrete_cement'] = pred[:, 0]\n",
    "pred_pd_temp['healthy_metal'] = pred[:, 1]\n",
    "pred_pd_temp['incomplete'] = pred[:, 2]\n",
    "pred_pd_temp['irregular_metal'] = pred[:, 3]\n",
    "pred_pd_temp['other'] = pred[:, 4]\n",
    "\n",
    "pred_pd = pd.merge(pred_pd, pred_pd_temp, on = 'id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "H23UGWdswFOQ"
   },
   "outputs": [],
   "source": [
    "pred_pd.to_csv(os.path.join(path, 'feature/mixed_inputs_mask.csv'), index = False)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "mixed_inputs_cnn_mask.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
